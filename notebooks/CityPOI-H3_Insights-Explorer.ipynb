{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d0123e-9528-4aa8-936d-17d4b38d8288",
   "metadata": {},
   "source": [
    "### CityPOI Explorer: H3 Indexing with Google Places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702caf5-68ab-43eb-9c81-0c18aaf97b60",
   "metadata": {},
   "source": [
    "Using Uber H3 spatial indexing to get city-wide POI data from **Google Places API** - developing a technique that leverages **Uber**'s H3 spatial indexing algorithm to extract Point of Interest (POI) data for large geographies / areas like cities from the Google Places API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c85508b-3c21-4b1a-9764-a154958ae14f",
   "metadata": {},
   "source": [
    "#### Setting up the Places API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f97d7a-13a5-4b1e-b60d-1a45c9e2b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U folium h3 tqdm ast geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e9484-bfc3-434b-9c8a-a689d38299b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import requests as re\n",
    "import folium\n",
    "import h3 \n",
    "import tqdm\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import ast\n",
    "\n",
    "from shapely import geometry\n",
    "from shapely.ops import unary_union, transform\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "# Please do not keep the API key in the open like this in\n",
    "# an actual experiment, please.\n",
    "API_KEY = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7ed7f-654e-40a4-9071-6e3eec4a39c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapefiles will be provided in the github repository\n",
    "districts_gpd = gpd.read_file('data/admin_boundaries/Adminbdy Shapefile/District_Boundary.shp')\n",
    "karachi_districts = ['KARACHI CENTRAL', 'KARACHI WEST', 'MALIR CANTONMENT',\n",
    "       'KORANGI CREEK CANTONMENT', 'MANORA CANTONMENT',\n",
    "       'CLIFTON CANTONMENT', 'KARACHI CANTONMENT', 'FAISAL CANTONMENT',\n",
    "       'KARACHI SOUTH', 'MALIR', 'KORANGI', 'KARACHI EAST']\n",
    "\n",
    "# Unary union to combine all districts into one polygon object\n",
    "khi_boundaries = unary_union(districts_gpd[districts_gpd\\\n",
    "  .DISTRICT\\\n",
    "  .isin(karachi_districts)==True]['geometry'])\n",
    "\n",
    "# Small buffer to smoothen the edges\n",
    "khi_boundaries = khi_boundaries.buffer(0.05)\n",
    "khi_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d78b05-c6cd-42be-8ef3-4b12b49839ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip coordinate sequence from longitude, latitude \n",
    "# to latitude, longitude as this is how the h3 API reads it\n",
    "def flip(x,y):\n",
    "    return y,x\n",
    "khi_boundaries = transform(flip,khi_boundaries)\n",
    "\n",
    "# Convert to polgyon geojson object\n",
    "khi_boundaries_gejson = gpd.GeoSeries([khi_boundaries])\\\n",
    "    .__geo_interface__['features'][0]['geometry']\n",
    "\n",
    "# Get h3 cell IDs for cells within the bounding polygon / geojson\n",
    "res6_khi_hex = h3.polyfill(khi_boundaries_gejson,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f0e7c-0635-404d-8b63-ce4acf2e65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hexagons(hexagons, color=\"red\", folium_map=None):\n",
    "    \"\"\"\n",
    "    original source: https://nbviewer.org/github/uber/h3-py-notebooks/blob/master/notebooks/usage.ipynb\n",
    "\n",
    "    hexagons is a list of hexcluster. Each hexcluster is a list of hexagons. \n",
    "    eg. [[hex1, hex2], [hex3, hex4]]\n",
    "    \"\"\"\n",
    "    polylines = []\n",
    "    lat = []\n",
    "    lng = []\n",
    "    for hex in hexagons:\n",
    "        polygons = h3.h3_set_to_multi_polygon([hex], geo_json=False)\n",
    "        # Flatten polygons into loops.\n",
    "        outlines = [loop for polygon in polygons for loop in polygon]\n",
    "        polyline = [outline + [outline[0]] for outline in outlines][0]\n",
    "        lat.extend(map(lambda v:v[0],polyline))\n",
    "        lng.extend(map(lambda v:v[1],polyline))\n",
    "        polylines.append(polyline)\n",
    "    \n",
    "    if folium_map is None:\n",
    "        m = folium\\\n",
    "            .Map(location=[sum(lat)/len(lat),\n",
    "                        sum(lng)/len(lng)],\n",
    "                        zoom_start=9, \n",
    "                        tiles='cartodbpositron')\n",
    "    else:\n",
    "        m = folium_map\n",
    "    for polyline in polylines:\n",
    "        my_PolyLine=folium.PolyLine(locations=polyline,weight=4,color=color)\n",
    "        m.add_child(my_PolyLine)\n",
    "    return m\n",
    "\n",
    "m = visualize_hexagons(hexagons=res6_khi_hex)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e43589-b16d-451a-befb-12395ee0f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_places_poi(lat,lng,resolution,type,api_key):\n",
    "    places_df = []\n",
    "\n",
    "    # nearby sarch API URL\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "    params = {\n",
    "    'location': f'{lat},{lng}',\n",
    "    'radius': resolution,\n",
    "    'types': type,\n",
    "    'key': api_key}\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    results = json.loads(response.content)\n",
    "    places_df.append(results['results'])\n",
    "\n",
    "    while 'next_page_token' in results:\n",
    "        time.sleep(1)\n",
    "        params['pagetoken'] = results['next_page_token']\n",
    "        response = requests.get(url,params=params)\n",
    "        results = json.loads(response.content)\n",
    "        places_df.append(results['results'])\n",
    "        \n",
    "    results_df = pd.concat([pd.DataFrame(df) for df in places_df])\n",
    "    results_df = results_df.reset_index(drop=True)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Location for Karachi DHA Phase 6, Khayaban-e-Sehar\n",
    "lat,lng = 24.794386, 67.048928\n",
    "\n",
    "# see all POI types for places API here: https://developers.google.com/maps/documentation/places/web-service/supported_types\n",
    "results_df = get_places_poi(lat=lat,lng=lng,\n",
    "                                 resolution=2000,\n",
    "                                 type='cafe', # \n",
    "                                 api_key=API_KEY)\n",
    "\n",
    "results_df[['place_id','name','types','user_ratings_total','vicinity']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b708f50d-a3f8-4cf6-95e3-9c96808e25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res6_khi_hex = pd.DataFrame({'hex_id':list(res6_khi_hex),'hex_resolution':6})\n",
    "\n",
    "res7_khi_hex = h3.polyfill(khi_boundaries_gejson,7)\n",
    "res7_khi_hex = pd.DataFrame({'hex_id':list(res7_khi_hex),'hex_resolution':7})\n",
    "\n",
    "res8_khi_hex = h3.polyfill(khi_boundaries_gejson,8)\n",
    "res8_khi_hex = pd.DataFrame({'hex_id':list(res8_khi_hex),'hex_resolution':8})\n",
    "\n",
    "res9_khi_hex = h3.polyfill(khi_boundaries_gejson,9)\n",
    "res9_khi_hex = pd.DataFrame({'hex_id':list(res9_khi_hex),'hex_resolution':9})\n",
    "\n",
    "khi_hex_df = pd.concat([res6_khi_hex,res7_khi_hex,res8_khi_hex,res9_khi_hex])\n",
    "khi_hex_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "def get_hex_radius(row,BUFFER):\n",
    "    edge_length = h3.edge_length(row.hex_resolution,'m')\n",
    "    radius = edge_length\n",
    "    radius = radius+edge_length*BUFFER\n",
    "    return radius\n",
    "\n",
    "khi_hex_df['hex_area'] = khi_hex_df.hex_id.apply(lambda x: h3.cell_area(x,unit='m^2'))\n",
    "khi_hex_df['hex_radius_places_api'] = khi_hex_df.apply(lambda row: get_hex_radius(row,0.15),axis=1)\n",
    "khi_hex_df['centroid'] = khi_hex_df.hex_id.apply(lambda x: h3.h3_to_geo(x))\n",
    "khi_hex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3a5a21-9997-4a16-8c21-15ca0e022cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res6 ~3700m\n",
    "#Get the highest resolution cells\n",
    "max_khi_hex_df = khi_hex_df[khi_hex_df.hex_resolution==khi_hex_df.hex_resolution.min()]\n",
    "\n",
    "# We created a seperate folder to store all output, in case the code is interrupted we can use\n",
    "# this list to make sure we're not repeating any cells.\n",
    "\n",
    "searched_cells = os.listdir(f'data/h3cell_output_cafe/')\n",
    "searched_cells = set([x.replace('.csv','') for x in searched_cells])\n",
    "\n",
    "# Setting POI type for cafe.\n",
    "type = 'cafe'\n",
    "\n",
    "for ind,row in tqdm.tqdm(max_khi_hex_df.iterrows(),\n",
    "                         total=max_khi_hex_df.shape[0]):\n",
    "    # Parsing the highest resolution cells and saving outputs in a csv file\n",
    "    h3_cell = row.hex_id\n",
    "    if(h3_cell not in searched_cells):\n",
    "        lat,lng = row.centroid[0],row.centroid[1]\n",
    "        resolution = row.hex_radius_places_api\n",
    "        # Call the Places using the the function we wrote earlier\n",
    "        df = func_get_places_poi(lat=lat,lng=lng,resolution=resolution,type=type,api_key=API_KEY)\n",
    "        df['hex_id'] = h3_cell\n",
    "        cell_save_path = f'data/h3cell_output_{type}/{h3_cell}.csv'\n",
    "        df.to_csv(cell_save_path,index=False)\n",
    "        \n",
    "        # Key part of the algorithm, if the API returns equal or more than 60 results\n",
    "        if(len(df)>=60):\n",
    "            cell_children = h3.h3_to_children(df['hex_id'][0])\n",
    "            child_df = khi_hex_df[khi_hex_df.hex_id.isin(cell_children)]\n",
    "            \n",
    "            #res 7 ~1400m\n",
    "            for ind,row in child_df.iterrows():\n",
    "                h3_cell = row.hex_id\n",
    "                lat,lng = row.centroid[0],row.centroid[1]\n",
    "                resolution = row.hex_radius_places_api\n",
    "                df = func_get_places_poi(lat=lat,lng=lng,resolution=resolution,type=type,api_key=API_KEY)\n",
    "                df['hex_id'] = h3_cell\n",
    "                cell_save_path = f'data/h3cell_output_{type}/{h3_cell}.csv'\n",
    "                df.to_csv(cell_save_path,index=False)\n",
    "\n",
    "                # Repeat same logic as above on all other resolutions  \n",
    "                if(len(df)>=60):\n",
    "                    cell_children = h3.h3_to_children(df['hex_id'][0])\n",
    "                    child_df = khi_hex_df[khi_hex_df.hex_id.isin(cell_children)]\n",
    "\n",
    "                    # res 8 ~500m\n",
    "                    for ind,row in child_df.iterrows():\n",
    "                        h3_cell = row.hex_id\n",
    "                        lat,lng = row.centroid[0],row.centroid[1]\n",
    "                        resolution = row.hex_radius_places_api\n",
    "                        df = func_get_places_poi(lat=lat,lng=lng,resolution=resolution,type=type,api_key=API_KEY)\n",
    "                        df['hex_id'] = h3_cell\n",
    "                        cell_save_path = f'data/h3cell_output_{type}/{h3_cell}.csv'\n",
    "                        df.to_csv(cell_save_path,index=False)\n",
    "\n",
    "                        # You can go as deep as you want, down to res 9 and res 10 similary\n",
    "                        # Yes, this should be a recursive funciton but I'll leave that to you? :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2cd10-fbb0-4ac2-93ff-2820caa15c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that the algorithm did search 34 lower resolution hexagons,\n",
    "# where we managed to saturate the API at a higher reesolution.\n",
    "paths = os.listdir('data/h3cell_output_cafe')\n",
    "paths = ['data/h3cell_output_cafe/' + path for path in paths]\n",
    "n_df = pd.concat([pd.read_csv(path) for path in paths])\n",
    "khi_hex_df[khi_hex_df\\\n",
    "           .hex_id\\\n",
    "           .isin(n_df.hex_id.unique())]\\\n",
    "           .hex_resolution.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1281410-ddf4-4441-8507-54ddb3b0a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important we first de-duplicate our data by using the place_id,\n",
    "# which is unique for each POI on Google Maps.\n",
    "n_df = n_df.drop_duplicates(subset='place_id')\n",
    "n_df = n_df.reset_index(drop=True)\n",
    "n_df['location'] = n_df.geometry.apply(lambda x: ast.literal_eval(x)['location'])\n",
    "n_df['lat'] = n_df['location'].apply(lambda x: x['lat'])\n",
    "n_df['lng'] = n_df['location'].apply(lambda x: x['lng'])\n",
    "for ind,row in n_df.iterrows():\n",
    "    lat = row.lat\n",
    "    lng = row.lng\n",
    "    folium.CircleMarker(location=(lat,lng),\n",
    "                        radius=5,\n",
    "                        color='blue').add_to(m)\n",
    "\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
