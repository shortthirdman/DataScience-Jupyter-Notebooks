{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1d44d3-78d9-4967-92b1-c6276ae2092e",
   "metadata": {},
   "source": [
    "## Prediction of Stock Prices Using Deep Learning\n",
    "\n",
    "Add indicators like sell and buy on chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb231e7f-3036-43f7-bf6c-9c9da890c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from importlib import reload # to reload modules if we made changes to them without restarting kernel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier # for features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ecdc4-f4f2-4c81-aa9e-b48d4d71e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.dpi'] = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e10545-3a4e-4144-b4a6-ffcb52a1357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, f1_score, accuracy_score\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "import functions\n",
    "import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e34ef-7540-4c52-ba8e-b0626a22a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.keras.optimizer_v2 import rmsprop\n",
    "from functools import partial\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Flatten, TimeDistributed, LSTM, Dense, Bidirectional, Dropout, ConvLSTM2D, Conv1D, GlobalMaxPooling1D, MaxPooling1D, Convolution1D, BatchNormalization, LeakyReLU\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d37a04-7eb4-4909-8ef2-d3827d99f8fa",
   "metadata": {},
   "source": [
    "Tell the `numpy` library to use the number 66 as its random seed. This means that every time the program is run, it will generate the same sequence of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86969c1f-3943-4a6f-908e-c4d4647841db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(66)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96175f19-5038-4587-b69a-0bb549cdecc9",
   "metadata": {},
   "source": [
    "Useful for machine learning because it allows to get consistent results each time notebook is executed/run. This is important because it allows to compare different models and algorithms fairly, and to make sure that the results are reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9edb28-e7ec-48fc-a29c-1a153dc11270",
   "metadata": {},
   "source": [
    "### Loading Data\r\n",
    "Reading stock datas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054585c6-5b82-460a-b67f-86b76aa08e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('data/stocks')\n",
    "stocks = {}\n",
    "for file in files:\n",
    "    if file.split('.')[1] == 'csv':\n",
    "        name = file.split('.')[0]\n",
    "        stocks[name] = pd.read_csv('data/stocks/'+file, index_col='Date')\n",
    "        stocks[name].index = pd.to_datetime(stocks[name].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b6726b-7a6b-4524-bec4-07e00dc7c432",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "The baseline prediction model is simply a model that predicts that the stock price will go up or down with a 50% chance. \n",
    "\n",
    "The accuracy of the baseline prediction model is calculated using the accuracy_score() function. This function takes in two arrays of predictions and labels and returns the percentage of predictions that were correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c2dd3-7b30-4737-9ed8-28e6f0b239f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(stock):\n",
    "    baseline_predictions = np.random.randint(0, 2, len(stock))\n",
    "    accuracy = accuracy_score(functions.binary(stock), baseline_predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7432a02-89e5-4f3a-a1a2-e0fbacab2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_accuracy = baseline_model(stocks['tsla'].Return)\n",
    "print('Baseline model accuracy: {:.1f}%'.format(baseline_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6bbb93-cfbc-469d-8a5c-8644264ba2f3",
   "metadata": {},
   "source": [
    "### Accuracy Distribution\n",
    "\n",
    "Visualize the accuracy of the baseline model. The histogram shows how many predictions were made for each accuracy level. The vertical line shows the average accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368aadbb-e764-41aa-a44c-9039ee91e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_preds = []\n",
    "for i in range(1000):\n",
    "    base_preds.append(baseline_model(stocks['tsla'].Return))\n",
    "    \n",
    "plt.figure(figsize=(16,6))\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.hist(base_preds, bins=50, facecolor='#4ac2fb')\n",
    "plt.title('Baseline Model Accuracy', fontSize=15)\n",
    "plt.axvline(np.array(base_preds).mean(), c='k', ls='--', lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd6d21-d2da-4db2-9526-e6df59cc5e76",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6d3ea3-89eb-4e9b-8b63-0edcf8fc40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tesla historical data contains {} entries'.format(stocks['tsla'].shape[0]))\n",
    "stocks['tsla'][['Return']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5de64ae-54d1-4ed5-9fe0-1be531ddcaa5",
   "metadata": {},
   "source": [
    "### Autocorrelation\n",
    "\n",
    "Plot the autocorrelation function (ACF) of the returns of `Tesla` stock.\n",
    "\n",
    "The ACF measures how correlated a stock’s returns are with its past returns at different time lags. The plot shows how this correlation changes over time, for up to 299 days.\n",
    "\n",
    "The ACF can be used to analyze historical stock returns to identify patterns in the stock’s price movements.\n",
    "\n",
    "For example, a positive ACF at a lag of 1 day suggests that the stock is more likely to go up if it has gone up in the previous day. This information could be used to develop a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1728e8c8-f837-4bdd-837f-3ce646ed6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (16, 3)\n",
    "plot_acf(stocks['tsla'].Return, lags=range(300))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdcc70c-3097-4d93-8226-3bea6e49e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = [(0,0,0),(1,0,0),(0,1,0),(0,0,1),(1,1,0)]\n",
    "\n",
    "train = list(stocks['tsla']['Return'][1000:1900].values)\n",
    "test = list(stocks['tsla']['Return'][1900:2300].values)\n",
    "\n",
    "all_predictions = {}\n",
    "\n",
    "for order in orders:\n",
    "    try:\n",
    "        history = train.copy()\n",
    "        order_predictions = []\n",
    "        \n",
    "        for i in range(len(test)):\n",
    "            \n",
    "            model = ARIMA(history, order=order) # defining ARIMA model\n",
    "            model_fit = model.fit(disp=0) # fitting model\n",
    "            y_hat = model_fit.forecast() # predicting 'return'\n",
    "            order_predictions.append(y_hat[0][0]) # first element ([0][0]) is a prediction\n",
    "            history.append(test[i]) # simply adding following day 'return' value to the model    \n",
    "            print('Prediction: {} of {}'.format(i+1,len(test)), end='\\r')\n",
    "        \n",
    "        accuracy = accuracy_score( \n",
    "            functions.binary(test), \n",
    "            functions.binary(order_predictions) \n",
    "        )        \n",
    "        print('                             ', end='\\r')\n",
    "        print('{} - {:.1f}% accuracy'.format(order, round(accuracy, 3)*100), end='\\n')\n",
    "        all_predictions[order] = order_predictions\n",
    "    \n",
    "    except:\n",
    "        print(order, '<== Wrong Order', end='\\n')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a0c8b6-6e8a-4caf-83b2-2357688e7392",
   "metadata": {},
   "source": [
    "### Review Predictions\n",
    "\n",
    "Plots a graph of the actual and predicted stock prices for a given period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03778da-da7b-41c2-9ace-912bc2cdf662",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4))\n",
    "plt.plot(test, label='Test', color='#4ac2fb')\n",
    "plt.plot(all_predictions[(0,1,0)], label='Predictions', color='#ff4e97')\n",
    "plt.legend(frameon=True, loc=1, ncol=1, fontsize=10, borderpad=.6)\n",
    "plt.title('Arima Predictions', fontSize=15)\n",
    "plt.xlabel('Days', fontSize=13)\n",
    "plt.ylabel('Returns', fontSize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac340102-1656-4e44-907f-883e52a572d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.annotate('',\n",
    "             xy=(15, 0.05), \n",
    "             xytext=(150, .2), \n",
    "             fontsize=10, \n",
    "             arrowprops={'width':0.4,'headwidth':7,'color':'#333333'}\n",
    "            )\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "rect = patches.Rectangle((0,-.05), 30, .1, ls='--', lw=2, facecolor='y', edgecolor='k', alpha=.5)\n",
    "ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d46cb-b0d6-4ac1-9223-a63f51494f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axes([.25, 1, .2, .5])\n",
    "plt.plot(test[:30], color='#4ac2fb')\n",
    "plt.plot(all_predictions[(0,1,0)][:30], color='#ff4e97')\n",
    "plt.tick_params(axis='both', labelbottom=False, labelleft=False)\n",
    "plt.title('Lag')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beb97a2-a045-49fa-bd85-879fdb53b9e9",
   "metadata": {},
   "source": [
    "### Histogram\n",
    "\n",
    "This code creates a histogram plot that compares the distribution of the actual and predicted stock returns for Tesla stock. The data used for the histogram is a subset of the Tesla stock returns from index 1900 to 2300.\n",
    "\n",
    "The actual stock returns are plotted in blue, while the predicted stock returns are plotted in pink with some transparency. A vertical dashed line at 0 is also plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c067a-b845-4cb4-b472-eb7f2e09a38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.hist(stocks['tsla'][1900:2300].reset_index().Return, bins=20, label='True', facecolor='#4ac2fb')\n",
    "plt.hist(all_predictions[(0,1,0)], bins=20, label='Predicted', facecolor='#ff4e97', alpha=.7)\n",
    "plt.axvline(0, c='k', ls='--')\n",
    "plt.title('ARIMA True vs Predicted Values Distribution', fontSize=15)\n",
    "plt.legend(frameon=True, loc=1, ncol=1, fontsize=10, borderpad=.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c696a8-3a06-44c8-8546-02c3f7c47d55",
   "metadata": {},
   "source": [
    "- If the distribution of the predicted values is very similar to the distribution of the actual values, then this suggests that the model is doing a good job of predicting the stock market.\n",
    "\n",
    "- If the distribution of the predicted values is significantly different from the distribution of the actual values, then this suggests that the model is not doing a good job of predicting the stock market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2819e64-eabf-4658-a10c-11b15a49232e",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "Sentiment analysis is a technique for extracting the sentiment of a piece of text, such as whether it is positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85641b24-fead-47b1-9763-8a4cff4407a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_headlines = pd.read_csv('data/tesla_headlines.csv', index_col='Date')\n",
    "\n",
    "tesla = stocks['tsla'].join(tesla_headlines.groupby('Date').mean().Sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affbb4e7-b944-4b67-8be1-e8d1de4f95f8",
   "metadata": {},
   "source": [
    "Combining the stock data with the sentiment data can provide valuable insights into how news headlines may be impacting Tesla’s stock price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64401734-b28b-4880-8524-a2f55a654c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db44aaf-5721-458c-a787-dc4183fa74d3",
   "metadata": {},
   "source": [
    "Machine learning algorithms can be trained on the combined stock and sentiment data to learn to predict future stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876d359-6588-44a5-9f9c-53a2bb01bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(tesla.loc['2019-01-10':'2019-09-05'].Sentiment.shift(1), c='#3588cf', label='News Sentiment')\n",
    "plt.plot(tesla.loc['2019-01-10':'2019-09-05'].Return, c='#ff4e97', label='Return')\n",
    "plt.legend(frameon=True, fancybox=True, framealpha=.9, loc=1)\n",
    "plt.title('Tesla News Sentiment and Daily Return', fontSize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75763495-c46c-4eab-adf1-385e2a0e9aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'Sentiment': tesla.loc['2019-01-10':'2019-09-05'].Sentiment.shift(1), \n",
    "    'Return': tesla.loc['2019-01-10':'2019-09-05'].Return}).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7643fcd-4f5f-4503-8abf-4633e5166d1d",
   "metadata": {},
   "source": [
    "The correlation coefficient is a measure of the strength and direction of the relationship between two variables.\n",
    "\n",
    "A correlation coefficient of 1 indicates a perfect positive correlation, while a correlation coefficient of -1 indicates a perfect negative correlation.\n",
    "\n",
    "A correlation coefficient of 0 indicates no correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fcc04f-1d60-4839-9b4c-fd51190b9a0c",
   "metadata": {},
   "source": [
    "The correlation coefficient between the Sentiment and Return columns will indicate the strength and direction of the relationship between news sentiment and stock returns for Tesla stock.\n",
    "\n",
    "A positive correlation coefficient would suggest that positive news sentiment tends to be associated with positive stock returns, while a negative correlation coefficient would suggest that negative news sentiment tends to be associated with negative stock returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b3256-3a0b-4612-b8d5-d23ba82facc9",
   "metadata": {},
   "source": [
    "### Feature Selection With XGBoost\n",
    "\n",
    "Scaling is a common technique used in machine learning to prepare data for training and prediction. Scaling helps to ensure that all of the features in the data have a similar scale, which can improve the performance of machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929de148-b15a-4a15-b7a9-6ce6ce67aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_tsla = functions.scale(stocks['tsla'], scale=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494f0e4-d0ed-496e-bbff-8cfd348bd0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_tsla[:-1]\n",
    "y = stocks['tsla'].Return.shift(-1)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7497f48-b665-41b0-84d9-c6dfa67c8195",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X[1500:], y[1500:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4712d5-8f98-4781-9342-a966cc2cc211",
   "metadata": {},
   "source": [
    "Create an instance of the `XGBClassifier` class, which is a machine learning algorithm used for classification.\n",
    "\n",
    "The fit() method is then called on the `XGBClassifier` instance, passing in a subset of the input data X and corresponding labels y. This fit() method trains the classifier on the provided data, allowing it to learn patterns and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d8368-791e-445e-9e51-9bdb5511b13e",
   "metadata": {},
   "source": [
    "The `XGBClassifier` algorithm is a type of gradient boosting algorithm, which is a machine learning technique that combines the predictions of multiple weak learners to produce a strong learner.\n",
    "\n",
    "Gradient boosting algorithms are known for their ability to handle complex data and achieve high accuracy on a variety of machine learning tasks, including classification and regression.\n",
    "\n",
    "The fit() method is a critical step in the machine learning process. It is during this step that the classifier learns the relationship between the input data X and the output labels y. Once the classifier is trained, it can be used to make predictions on new data.\r\n",
    "\r\n",
    "Th`e XGBClassifi`er algorithm is a powerful tool for machine learning. It can be used to solve a wide variety of classification problems, including spam filtering, fraud detection, and medical diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b88b11-a9c7-45e5-8894-e0aed556a7e0",
   "metadata": {},
   "source": [
    "### Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75e7129-a8f8-4c1b-adf1-625160de85c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 21\n",
    "scaled_tsla = functions.scale(stocks['tsla'], scale=(0,1))\n",
    "\n",
    "\n",
    "X_train, \\\n",
    "y_train, \\\n",
    "X_test, \\\n",
    "y_test = functions.split_sequences(\n",
    "                        \n",
    "    scaled_tsla.to_numpy()[:-1], \n",
    "    stocks['tsla'].Return.shift(-1).to_numpy()[:-1], \n",
    "    n_steps, \n",
    "    split=True, \n",
    "    ratio=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5231988-2b3f-4f3d-8383-2a9e901f919b",
   "metadata": {},
   "source": [
    "Prepare the data for stock prediction using machine learning by scaling the input data and splitting it into training and testing sets.\n",
    "\n",
    "The training set will be used to train the machine learning model, and the testing set will be used to evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc168cf-18d5-44e1-964a-01de561f67ef",
   "metadata": {},
   "source": [
    "### LSTM Network\n",
    "\n",
    "Implementing a stock prediction model using machine learning using `Keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84285c88-81f6-463b-9f06-1eb74a14383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "n_steps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=False))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f92ec6-2c32-44bf-b129-4a973d386c64",
   "metadata": {},
   "source": [
    "A Sequential model is a linear stack of layers. The model architecture consists of two LSTM (Long Short-Term Memory) layers.\n",
    "\n",
    "LSTM layers are a type of recurrent neural network (RNN) that are well-suited for time series forecasting tasks. LSTM layers are able to learn long-term dependencies in the data, which is important for stock prediction.\n",
    "\n",
    "The first LSTM layer in the model has 100 units and uses the ReLU activation function. It returns sequences of outputs. The input shape is determined by the number of time steps and features.\n",
    "\n",
    "The second LSTM layer in the model has 50 units and also uses the ReLU activation function. It does not return sequences of outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4872bf5c-2e85-4572-afce-2ad20f63f700",
   "metadata": {},
   "source": [
    "After the LSTM layers, there are two Dense layers. Dense layers are a type of fully connected neural network layer. The first Dense layer in the model has 10 units. The second Dense layer has 1 unit.\r\n",
    "\r\n",
    "The second Dense layer outputs the prediction for the next day’s stock price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f66d78-91b6-48e3-969b-cbc4047ce0e5",
   "metadata": {},
   "source": [
    "The model is compiled using the `Adam Optimizer`, `mean squared error (mse)` as the loss function, and `mean absolute error (mae)` as the metric.\n",
    "\n",
    "The Adam optimizer is a popular optimizer for training machine learning models. It is known for its ability to converge quickly to good solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb18acab-371e-4890-b8c7-341c188d95d9",
   "metadata": {},
   "source": [
    "`Mean squared error (mse)` is a common loss function for regression tasks. It measures the average squared difference between the predicted values and the actual values.\n",
    "\n",
    "`Mean absolute error (mae)` is another common loss function for regression tasks. It measures the average absolute difference between the predicted values and the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75749597-e2ef-4d48-99d7-2008eeee9aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate a summary of a machine learning model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8de2ed-ae1f-4762-8736-c29cc440f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=100, verbose=0, validation_data=[X_test, y_test], use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2537b-839c-4b2f-83fc-b6f312b5c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(model.history.history['loss'], label='Loss')\n",
    "plt.plot(model.history.history['val_loss'], label='Val Loss')\n",
    "plt.legend(loc=1)\n",
    "plt.title('LSTM - Training Process')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85014b6b-fa60-43e5-8068-ea2f0dab2f95",
   "metadata": {},
   "source": [
    "Epochs - An epoch is a single iteration over the entire training dataset. During each epoch, the model is trained on all of the training data.\r\n",
    "\r\n",
    "Validao_n- : Validation is the process of evaluating the performance of a machine learning model on a dataset that it has not been trained on. This helps to ensure that the model is not overfitting to the training daa__\r\n",
    "\r\n",
    "Multipri_  - ng: Multiprocessing is a technique that allows multiple processes to run simultaneously. This can improve the performance of machine learning algorithms, especially when training on large daa\n",
    "t_\n",
    "__\n",
    ": - oss: The loss value is a measure of the difference between the predicted and actual values during training. The goal of training a machine learning model is to minimize the lsv\n",
    "a__lue.\r\n",
    "\r\n",
    "ioatL_o: -n loss: The validation loss value is a measure of the difference between the predicted and actual values during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc67c4-9c13-48cf-9d08-d2ef900900a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, y_true, y_pred = functions.evaluation(\n",
    "                    X_test, y_test, model, random=False, n_preds=50, \n",
    "                    show_graph=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
